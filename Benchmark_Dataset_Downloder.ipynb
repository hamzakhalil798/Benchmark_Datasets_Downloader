{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Mounting Drive(Optional)\n",
        "### -If want to save dataset on drive"
      ],
      "metadata": {
        "id": "gj-WFlI4c11k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Fj9me0pUc1fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installing Dependencies"
      ],
      "metadata": {
        "id": "YETMX9Ivc9Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hn_wPcBdBLO",
        "outputId": "13598207-c19c-4276-a63e-1de9d6548167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining Variables"
      ],
      "metadata": {
        "id": "lIY8ZczImsFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "dataset=\"Imagenet\" #@param ['Imagenet', \"gldv2_dataset/tfrecord\", \"VNC\", \"mvtec\", \"data/WIDER\", \"coco/images\",\"IXI_data\",\"edges2handbags\"]"
      ],
      "metadata": {
        "id": "0LW9bXvAdLrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MS COCO DATASET"
      ],
      "metadata": {
        "id": "ekiQaI76dQgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dataset) is False:\n",
        "  print(\"Downloading Data\")\n",
        "  os.makedirs(dataset_coco, exist_ok=True)\n",
        "  !wget  http://images.cocodataset.org/zips/val2017.zip -O coco/images/val2017.zip\n",
        "  !wget  http://images.cocodataset.org/zips/train2017.zip -O coco/images/train2017.zip\n",
        "  !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O coco/annotations_trainval2017.zip\n",
        "  \n",
        "\n",
        "  !unzip coco/images/val2017.zip -d coco/images\n",
        "  !unzip coco/images/train2017.zip -d coco/images\n",
        "  !unzip coco/annotations_trainval2017.zip -d coco\n",
        "  \n",
        "else:\n",
        "  print('Data already Downlaoded')\n"
      ],
      "metadata": {
        "id": "18bd1HSfdTh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MVtec Dataset"
      ],
      "metadata": {
        "id": "XqJt7PaMeA8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.exists(dataset) is False:\n",
        "  print(\"Downloading Dataset\")\n",
        "  os.makedirs('mvtec')\n",
        "  # # Download MVTec anomaly detection dataset\n",
        "  !wget https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420938113-1629952094/mvtec_anomaly_detection.tar.xz\n",
        "  !tar -xf mvtec_anomaly_detection.tar.xz -C mvtec\n",
        "  !rm mvtec_anomaly_detection.tar.xz\n",
        "\n",
        "else:\n",
        "  print('Dataset already Downloaded')"
      ],
      "metadata": {
        "id": "7I_0qgHyeNcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wider Faces Dataset"
      ],
      "metadata": {
        "id": "_lOX-NIOgGHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dataset) is False:\n",
        "  print(\"Downloading Dataset\")\n",
        "  os.makedirs(dataset_wider, exist_ok=True)\n",
        "  !wget https://huggingface.co/datasets/wider_face/resolve/main/data/WIDER_train.zip -O data/WIDER/WIDER_train.zip\n",
        "  !wget https://huggingface.co/datasets/wider_face/resolve/main/data/WIDER_val.zip -O data/WIDER/WIDER_val.zip\n",
        "  !wget https://huggingface.co/datasets/wider_face/resolve/main/data/WIDER_test.zip -O data/WIDER/WIDER_test.zip\n",
        "  !wget http://shuoyang1213.me/WIDERFACE/support/bbx_annotation/wider_face_split.zip -O data/WIDER/wider_face_split.zip\n",
        "  !unzip data/WIDER/WIDER_train.zip -d data/WIDER\n",
        "  !unzip data/WIDER/WIDER_test.zip -d data/WIDER\n",
        "  !unzip data/WIDER/WIDER_val.zip -d data/WIDER\n",
        "  !unzip data/WIDER/wider_face_split.zip -d data/WIDER\n",
        "else:\n",
        "  print('dataset already present')"
      ],
      "metadata": {
        "id": "ZSONIbWGgJYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VNC Dataset"
      ],
      "metadata": {
        "id": "16cbcyF3hO4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dataset) is False:\n",
        "  print(\"Downloading Dataset\")\n",
        "  os.makedirs(dataset_vnc, exist_ok=True)\n",
        "  !wget https://github.com/hayashimasa/UNet-PyTorch/raw/main/data/test-volume.tif -O VNC/test-volume.tif\n",
        "  !wget https://github.com/hayashimasa/UNet-PyTorch/raw/main/data/train-labels.tif -O VNC/train-labels.tif\n",
        "  !wget https://github.com/hayashimasa/UNet-PyTorch/raw/main/data/train-volume.tif -O VNC/train-volume.tif\n",
        "else:\n",
        "  print('Dataset Already Downloaded')"
      ],
      "metadata": {
        "id": "D-c8o66NhDUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CityScapes Dataset\n",
        "### The script takes the following parameters, in order:\n",
        "### - number of image files from the TRAIN split to download (maximum 500)\n",
        "### - number of image files from the INDEX split to download (maximum 100)\n",
        "### - number of image files from the TEST split to download (maximum 20)"
      ],
      "metadata": {
        "id": "Ss63Qy2akKyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dataset) is False:\n",
        "  print(\"Downloading Dataset\")\n",
        "  os.makedirs(dataset_google)\n",
        "  !bash download_dataset.sh 500 100 20\n",
        "\n",
        "else:\n",
        "  print('Dataset already Downloaded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgrXFLJgiviQ",
        "outputId": "17201f8f-e705-4e41-be31-dbc975f60a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset\n",
            "Folder gldv2_dataset already exists. Skipping folder creation.\n",
            "Creating folder gldv2_dataset/train.\n",
            "Successfully created folder gldv2_dataset/train.\n",
            "Downloading file https://s3.amazonaws.com/google-landmark/metadata/train.csv to folder gldv2_dataset/train.\n",
            "Downloading file https://s3.amazonaws.com/google-landmark/metadata/train_clean.csv to folder gldv2_dataset/train.\n",
            "Downloading file https://s3.amazonaws.com/google-landmark/metadata/train_attribution.csv to folder gldv2_dataset/train.\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mini ImageNet Dataset"
      ],
      "metadata": {
        "id": "7_wnJk2sqEa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dataset) is False:\n",
        "  print(\"Downloading Dataset\")\n",
        "\n",
        "  !gdown https://drive.google.com/u/0/uc?id=1HkgrkAwukzEZA0TpO7010PkAOREb2Nuk&export=download\n",
        "  !unzip mini-imagenet.zip \n",
        "else:\n",
        "  print('Dataset already Downloaded')"
      ],
      "metadata": {
        "id": "fFmLTNU7qGEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IXI Dataset\n",
        "### Contains BRAIN MRI Volumes. Dataset is Processed and saved as pkl"
      ],
      "metadata": {
        "id": "dRq1mYOi8F8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dataset) is False:\n",
        "  print('Downloading Dataset')\n",
        "\n",
        "\n",
        "  !gdown https://drive.google.com/u/0/uc?id=1-VQewCVNj5eTtc3eQGhTM2yXBQmgm8Ol&export=download\n",
        "  !unzip IXI_data.zip\n",
        "else:\n",
        "  print('Dataset Already Downloaded')"
      ],
      "metadata": {
        "id": "gErNWIPs8Hmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Edges2Handbags"
      ],
      "metadata": {
        "id": "sNV8z5Wh9JBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dataset) is False:\n",
        "  print(\"Downloading Dataset\")\n",
        "  !wget http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/edges2handbags.tar.gz\n",
        "  !tar -xvzf edges2handbags.tar.gz\n",
        "else:\n",
        "  print('Dataset Already Downloaded')"
      ],
      "metadata": {
        "id": "p1IUls_h9Kzk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}